{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "\n",
        "### How to use a logistic classification regression model to predict Churn on pre-processed Google Analytics 4 data using  BigQueryML\n",
        "\n",
        "[original source](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/bigquery_ml/bqml-online-prediction.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this tutorial, you learn how to train and deploy a churn prediction model for real-time inference, with the data in BigQuery and model trained using BigQuery ML, registered to Vertex AI Model Registry, and deployed to an endpoint on Vertex AI for online predictions.\n",
        "\n",
        "This tutorial uses the following Google Cloud data analytics and ML services:\n",
        "\n",
        "- BigQuery\n",
        "- BigQuery ML\n",
        "- Vertex AI Model Registry\n",
        "- Vertex endpoints\n",
        "\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Using Python & SQL to query the public data in BigQuery\n",
        "- Preparing the data for modeling\n",
        "- Training a classification model using BigQuery ML and registering it to Vertex AI Model Registry\n",
        "- Inspecting the model on Vertex AI Model Registry\n",
        "- Deploying the model to an endpoint on Vertex AI\n",
        "- Making sample online predictions to the model endpoint\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c640527e06e6"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "The dataset, <a href=\"https://console.cloud.google.com/bigquery?project=bigquery-public-data&d=ga4_obfuscated_sample_ecommerce&p=bigquery-public-data&page=dataset\" target=\"_blank\">available publicly on BigQuery</a>, comes from obfuscated <a href=\"https://support.google.com/analytics/answer/10937659\" target=\"_blank\">Google Analytics 4 data</a> from the <a href=\"https://shop.googlemerchandisestore.com/\" target=\"_blank\">Google Merchandise Store</a>)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "### Install additional packages\n",
        "\n",
        "Install the following packages required to execute this notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b4ef9b72d43",
        "outputId": "52ab99ac-5621-4c15-e2ec-1db46dae5e35"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# The Vertex AI Workbench Notebook product has specific requirements\n",
        "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
        "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
        "    \"/opt/deeplearning/metadata/env_version\"\n",
        ")\n",
        "\n",
        "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
        "USER_FLAG = \"\"\n",
        "if IS_WORKBENCH_NOTEBOOK:\n",
        "    USER_FLAG = \"--user\"\n",
        "\n",
        "! pip3 install --upgrade google-cloud-aiplatform {USER_FLAG} -q google-cloud-bigquery db-dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhq5zEbGg0XX"
      },
      "source": [
        "### Restart the kernel\n",
        "\n",
        "After you install the additional packages, you need to restart the notebook kernel so it can find the packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzrelQZ22IZj"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eqwLyLiibss"
      },
      "source": [
        "## Project Variables "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBUd-MvjhFDR"
      },
      "outputs": [],
      "source": [
        "# Project variables \n",
        "#\n",
        "# These are the project variable used in this ML Model: \n",
        "#\n",
        "\n",
        "PROJECT_ID = \"\" # @param {type:\"string\"}\n",
        "bqml_type = \"log_reg\" # @param {type:\"string\"}\n",
        "BQML_MODEL_NAME = \"bqml_log_reg_analytics_churn_predict_model\"\n",
        "job_display_name = BQML_MODEL_NAME + \"_job\"\n",
        "ENDPOINT_NAME = BQML_MODEL_NAME + \"_endpoint\"\n",
        "\n",
        "# datasets\n",
        "BQ_DATASET_NAME = BQML_MODEL_NAME + \"_dataset\"\n",
        "sql_create_dataset = f\"\"\"CREATE SCHEMA IF NOT EXISTS {BQ_DATASET_NAME}\"\"\"\n",
        "\n",
        "# bucket details\n",
        "BUCKET_NAME = \"bqml_tutorials\"\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}/{bqml_type}/\"\n",
        "OUTPUTBUCKET = f\"gs://bqml_datasets_predictions/{bqml_type}/\"\n",
        "\n",
        "# Region \n",
        "REGION = \"us-central1\" # @param {type: \"string\"} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJYoRfYng0XZ"
      },
      "source": [
        "Otherwise, set your project ID here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable, which is used for operations\n",
        "throughout the rest of this notebook.  Below are regions supported for Vertex AI. We recommend that you choose the region closest to you.\n",
        "\n",
        "- Americas: `us-central1`\n",
        "- Europe: `europe-west4`\n",
        "- Asia Pacific: `asia-east1`\n",
        "\n",
        "You might not be able to use a multi-regional bucket for training with Vertex AI. Not all regions provide support for all Vertex AI services.\n",
        "\n",
        "Learn more about <a href=\"https://cloud.google.com/vertex-ai/docs/general/locations\" target=\"_blank\">Vertex AI regions</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "# If you are running this notebook in Colab, run this cell and follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# If on Vertex AI Workbench, then don't execute this code\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
        "    \"DL_ANACONDA_HOME\"\n",
        "):\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        from google.colab import auth as google_auth\n",
        "\n",
        "        google_auth.authenticate_user()\n",
        "\n",
        "    # If you are running this notebook locally, replace the string below with the\n",
        "    # path to your service account key and run this cell to authenticate your GCP\n",
        "    # account.\n",
        "    elif not os.getenv(\"IS_TESTING\"):\n",
        "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "set_service_account",
        "outputId": "69bd98d4-be56-4923-a881-f838cb7b9468"
      },
      "outputs": [],
      "source": [
        "SERVICE_ACCOUNT = \"\"  # @param {type:\"string\"}\n",
        "print(SERVICE_ACCOUNT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "autoset_service_account",
        "outputId": "668a8b3f-3a3d-4e68-ad51-633e01185a21"
      },
      "outputs": [],
      "source": [
        "if (\n",
        "    SERVICE_ACCOUNT == \"\"\n",
        "    or SERVICE_ACCOUNT is None\n",
        "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
        "):\n",
        "    # Get your service account from gcloud\n",
        "    if not IS_COLAB:\n",
        "        shell_output = !gcloud auth list 2>/dev/null\n",
        "        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
        "\n",
        "    else:  # IS_COLAB:\n",
        "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
        "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
        "\n",
        "    print(\"Service Account:\", SERVICE_ACCOUNT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEqT2Y4DJmf"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRUOFELefqf1"
      },
      "outputs": [],
      "source": [
        "from typing import Union\n",
        "\n",
        "import google.cloud.aiplatform as vertex_ai\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "### Initialize Vertex AI and BigQuery SDKs for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toA0pXPnZ2f-"
      },
      "outputs": [],
      "source": [
        "vertex_ai.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83859376c893"
      },
      "source": [
        "Create the BigQuery client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ab485806b17"
      },
      "outputs": [],
      "source": [
        "bq_client = bigquery.Client(project=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f94734ac9312"
      },
      "source": [
        "Use a helper function for sending queries to BigQuery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e364dab1d353"
      },
      "outputs": [],
      "source": [
        "# Wrapper to use BigQuery client to run query/job, return job ID or result as DF\n",
        "def run_bq_query(sql: str) -> Union[str, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Input: SQL query, as a string, to execute in BigQuery\n",
        "    Returns the query results as a pandas DataFrame, or error, if any\n",
        "    \"\"\"\n",
        "\n",
        "    # Try dry run before executing query to catch any errors\n",
        "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
        "    bq_client.query(sql, job_config=job_config)\n",
        "\n",
        "    # If dry run succeeds without errors, proceed to run query\n",
        "    job_config = bigquery.QueryJobConfig()\n",
        "    client_result = bq_client.query(sql, job_config=job_config)\n",
        "\n",
        "    job_id = client_result.job_id\n",
        "\n",
        "    # Wait for query/job to finish running. then get & return data frame\n",
        "    df = client_result.result().to_arrow().to_pandas()\n",
        "    print(f\"Finished job_id: {job_id}\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4a686de97f5"
      },
      "source": [
        "## BigQuery ML Model Training & Validation\n",
        "\n",
        "BigQuery ML (BQML) provides the capability to train ML tabular models, such as classification, regression, forecasting, and matrix factorization, in BigQuery using SQL syntax directly. BigQuery ML uses the scalable infrastructure of BigQuery ML so you don't need to set up additional infrastructure for training or batch serving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "088e3b9577b3",
        "outputId": "b1dcb351-cb97-412e-9ea2-a31082abd521"
      },
      "outputs": [],
      "source": [
        "sql_create_dataset = f\"\"\"CREATE SCHEMA IF NOT EXISTS {BQ_DATASET_NAME}\"\"\"\n",
        "\n",
        "print(sql_create_dataset)\n",
        "\n",
        "run_bq_query(sql_create_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13b6ce9f8d8b"
      },
      "source": [
        "### Using logistic regression model for classification on pre-processed Google Analytics 4 data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49dd00d5fbe5"
      },
      "source": [
        "Inpect data that has been pre-processed from <a href=\"https://support.google.com/analytics/answer/10937659\" target=\"_blank\">Google Analytics 4 data from the Google Merchandise Store</a> so that it can be used for classification. For more information on how this data was prepared, read <a href=\"https://cloud.google.com/blog/topics/developers-practitioners/churn-prediction-game-developers-using-google-analytics-4-ga4-and-bigquery-ml\" target=\"_blank\">this blog post</a>.\n",
        "\n",
        "As seen below, each row represents a single user, and the columns represent their demographic features, their aggregated behavioral features in the first 24 hours of visiting the Google Merchandise Store, and the label (whether the user churned or returned any time after the first 24 hours)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "0916b03610bd",
        "outputId": "40e2b989-8ef9-49a5-b98d-0f8ad40c51af"
      },
      "outputs": [],
      "source": [
        "sql_inspect = \"\"\"\n",
        "SELECT\n",
        "    *\n",
        "FROM\n",
        "    `bqmlpublic.demo_ga4churnprediction.training_data`\n",
        "LIMIT\n",
        "    100\n",
        "\"\"\"\n",
        "run_bq_query(sql_inspect)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02f304053600"
      },
      "source": [
        "### Train a classification model using BigQuery ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "566f3395f20b"
      },
      "source": [
        "The query below trains a logistic regression model using BigQuery ML. BigQuery resources are used to train the model.\n",
        "\n",
        "In the `OPTIONS` parameter:\n",
        "* with `model_registry=\"vertex_ai\"`, the BigQuery ML model will automatically be <a href=\"https://cloud.google.com/vertex-ai/docs/model-registry/model-registry-bqml\" target=\"_blank\">registered to Vertex AI Model Registry</a>, which enables you to view all of your registered models and its versions on Google Cloud in one place.\n",
        "\n",
        "* `vertex_ai_model_version_aliases allows you to set aliases to help you keep track of your model version (<a href=\"https://cloud.google.com/vertex-ai/docs/model-registry/model-alias\" target=\"_blank\">documentation</a>)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "414c45011c1f",
        "outputId": "26f411df-0f90-4d4c-df8e-86960ef8d6c5"
      },
      "outputs": [],
      "source": [
        "# this cell may take ~1 min to run\n",
        "\n",
        "sql_train_model_bqml = f\"\"\"\n",
        "CREATE OR REPLACE MODEL {BQ_DATASET_NAME}.{BQML_MODEL_NAME}    \n",
        "OPTIONS(\n",
        "  MODEL_TYPE=\"LOGISTIC_REG\",\n",
        "  input_label_cols=[\"churned\"],\n",
        "  model_registry=\"vertex_ai\",\n",
        "  vertex_ai_model_version_aliases=['logistic_reg', 'experimental']\n",
        ") AS\n",
        "\n",
        "SELECT\n",
        "  * EXCEPT(user_first_engagement, user_pseudo_id)\n",
        "FROM\n",
        "  bqmlpublic.demo_ga4churnprediction.training_data\n",
        "\"\"\"\n",
        "\n",
        "print(sql_train_model_bqml)\n",
        "\n",
        "run_bq_query(sql_train_model_bqml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a90e98c72a05"
      },
      "source": [
        "### Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aaaae772f67"
      },
      "source": [
        "With the model created, you can now evaluate the logistic regression model. Behind the scenes, BigQuery ML automatically <a href=\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create#data_split_method\" target=\"_blank\">split the data</a>, which makes it easier to quickly train and evaluate models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "a1f8ac93d570",
        "outputId": "ba0b0563-f88b-4d86-8dbf-20917f234733"
      },
      "outputs": [],
      "source": [
        "sql_evaluate_model = f\"\"\"\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.EVALUATE(MODEL {BQ_DATASET_NAME}.{BQML_MODEL_NAME})\n",
        "\"\"\"\n",
        "\n",
        "print(sql_evaluate_model)\n",
        "\n",
        "run_bq_query(sql_evaluate_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9f807a50f38"
      },
      "source": [
        "These metrics help you understand the performance of the model. \n",
        "\n",
        "There are various metrics for logistic regression and other model types (full list of metrics can be found in the <a href=\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate#mlevaluate_output\" target=\"_blank\">documentation</a>)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e806ebc48a2"
      },
      "source": [
        "### Batch prediction (with Explainable AI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d31605829283"
      },
      "source": [
        "Make a batch prediction in BigQuery ML on the original training data to check the probability of churn for each of the users, as seen in the `probability` column, with the predicted label under the `predicted_churn` column.\n",
        "\n",
        "<a href=\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-explain-predict\" target=\"_blank\">ML.EXPLAIN_PREDICT</a> has built-in <a href=\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-xai-overview\" target=\"_blank\">Explainable AI</a>. This allows you to see the top contributing features to each prediction and interpret how it was computed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "2d500fdbfb44",
        "outputId": "51f49c7c-2990-4bb9-8d87-768d8bd9836d"
      },
      "outputs": [],
      "source": [
        "sql_explain_predict = f\"\"\"\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.EXPLAIN_PREDICT(MODEL {BQ_DATASET_NAME}.{BQML_MODEL_NAME},\n",
        "    (SELECT * FROM bqmlpublic.demo_ga4churnprediction.training_data LIMIT 100)\n",
        "    )\n",
        "\"\"\"\n",
        "\n",
        "print(sql_explain_predict)\n",
        "\n",
        "run_bq_query(sql_explain_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa1f96c0f452"
      },
      "source": [
        "Since the `top_feature_attributions` is a nested column, you can unnest the array (<a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/arrays\" target=\"_blank\">documentation</a>) into separate rows for each of the features. In other words, since ML.EXPLAIN_PREDICT provides the top 5 most important features, using `UNNEST` results in 5 rows per prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "278b3441084b",
        "outputId": "07934242-2bac-4554-e89f-bb8c1336253c"
      },
      "outputs": [],
      "source": [
        "sql_explain_predict = f\"\"\"\n",
        "SELECT\n",
        "  tfa.*,\n",
        "  predicted_churned,\n",
        "  probability,\n",
        "  baseline_prediction_value,\n",
        "  prediction_value,\n",
        "  approximation_error,\n",
        "  user_pseudo_id\n",
        "FROM\n",
        "  ML.EXPLAIN_PREDICT(MODEL {BQ_DATASET_NAME}.{BQML_MODEL_NAME},\n",
        "    (SELECT * FROM bqmlpublic.demo_ga4churnprediction.training_data LIMIT 100)\n",
        "    ),\n",
        "  UNNEST(top_feature_attributions) as tfa\n",
        "WHERE\n",
        "  user_pseudo_id = \"7666337.2408476627\"\n",
        "\"\"\"\n",
        "\n",
        "print(sql_explain_predict)\n",
        "\n",
        "run_bq_query(sql_explain_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc0c1c1b03f9"
      },
      "source": [
        "### Inspect the model on Vertex AI Model Registry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0144d67a298e"
      },
      "source": [
        "When the model was trained in BigQuery ML, the line `model_registry=\"vertex_ai\"` registered the model to Vertex AI Model Registry automatically upon completion.\n",
        "\n",
        "You can view the model on the <a href=\"https://console.cloud.google.com/vertex-ai/models\" target=\"_blank\">Vertex AI Model Registry page</a>, or use the code below to check that it was successfully registered:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b00664302839",
        "outputId": "a7e0a51c-7b77-411e-fed1-510ecc6b420b"
      },
      "outputs": [],
      "source": [
        "model = vertex_ai.Model(model_name=BQML_MODEL_NAME)\n",
        "\n",
        "print(model.gca_resource)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89455f708f54"
      },
      "source": [
        "### Deploy the model to an endpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6120dcc1ff6"
      },
      "source": [
        "While BigQuery ML supports batch prediction with <a href=\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict\" target=\"_blank\">ML.PREDICT</a> and <a href=\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-explain-predict\" target=\"_blank\">ML.EXPLAIN_PREDICT</a>, BigQuery ML is not suitable for real-time predictions where you need low latency predictions with potentially high frequency of requests.\n",
        "\n",
        "In other words, deploying the BigQuery ML model to an endpoint enables you to do online predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ab7e1ac83c"
      },
      "source": [
        "#### Create a Vertex AI endpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a61ea55f685"
      },
      "source": [
        "To deploy your model to an endpoint, you will first need to create an endpoint before you deploy the model to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7d80941cf30",
        "outputId": "218b4cb2-3641-47fa-cae0-02fde15d46a7"
      },
      "outputs": [],
      "source": [
        "\n",
        "endpoint = vertex_ai.Endpoint.create(\n",
        "    display_name=ENDPOINT_NAME,\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        ")\n",
        "\n",
        "print(endpoint.display_name)\n",
        "print(endpoint.resource_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b58a104207d2"
      },
      "source": [
        "#### List endpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "951ed1693f6b"
      },
      "source": [
        "List the endpoints to make sure it has successfully been created. (You can also view your endpoints on the <a href=\"https://console.cloud.google.com/vertex-ai/endpoints\" target=\"_blank\">Vertex AI Endpoints page</a>)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4d7707910bc",
        "outputId": "3cafc8ad-57fb-416a-9160-29dad7cd4e26"
      },
      "outputs": [],
      "source": [
        "endpoint.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba0d40b26cfb"
      },
      "source": [
        "#### Deploy model to Vertex endpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a90be5b77a2"
      },
      "source": [
        "With the new endpoint, you can now deploy your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c70ecc568ee5",
        "outputId": "5b1e109c-1207-41b8-8b48-8afa710b10d7"
      },
      "outputs": [],
      "source": [
        "# deploying the model to the endpoint may take 10-15 minutes\n",
        "model.deploy(endpoint=endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c303d779477b"
      },
      "source": [
        "You can also check on the status of your model by visiting the <a href=\"https://console.cloud.google.com/vertex-ai/endpoints\" target=\"_blank\">Vertex AI Endpoints page</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cb04d49c6f1"
      },
      "source": [
        "### Make online predictions to the endpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a888784de7b"
      },
      "source": [
        "Using a sample of the training data, you can test the endpoint to make online predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f17b049a846c"
      },
      "outputs": [],
      "source": [
        "df_sample_requests_list = [\n",
        "    {\n",
        "        \"country\": \"Turkey\",\n",
        "        \"operating_system\": \"Web\",\n",
        "        \"language\": \"None\",\n",
        "        \"cnt_user_engagement\": 28,\n",
        "        \"cnt_page_view\": 37,\n",
        "        \"cnt_view_item\": 6,\n",
        "        \"cnt_view_promotion\": 15,\n",
        "        \"cnt_select_promotion\": 4,\n",
        "        \"cnt_add_to_cart\": 0,\n",
        "        \"cnt_begin_checkout\": 0,\n",
        "        \"cnt_add_shipping_info\": 0,\n",
        "        \"cnt_add_payment_info\": 0,\n",
        "        \"cnt_purchase\": 0,\n",
        "        \"month\": 1,\n",
        "        \"julianday\": 1,\n",
        "        \"dayofweek\": 6,\n",
        "    },\n",
        "    {\n",
        "        \"country\": \"Macao\",\n",
        "        \"operating_system\": \"Web\",\n",
        "        \"language\": \"None\",\n",
        "        \"cnt_user_engagement\": 2,\n",
        "        \"cnt_page_view\": 4,\n",
        "        \"cnt_view_item\": 0,\n",
        "        \"cnt_view_promotion\": 0,\n",
        "        \"cnt_select_promotion\": 0,\n",
        "        \"cnt_add_to_cart\": 0,\n",
        "        \"cnt_begin_checkout\": 0,\n",
        "        \"cnt_add_shipping_info\": 0,\n",
        "        \"cnt_add_payment_info\": 0,\n",
        "        \"cnt_purchase\": 0,\n",
        "        \"month\": 1,\n",
        "        \"julianday\": 16,\n",
        "        \"dayofweek\": 7,\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4839f31d2f8",
        "outputId": "f1123511-3f61-461b-8949-01ae90223030"
      },
      "outputs": [],
      "source": [
        "prediction = endpoint.predict(df_sample_requests_list)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "347ffda86396"
      },
      "source": [
        "You can then extract the predictions from the prediction response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea659b7c178d",
        "outputId": "9b20e873-74ea-4491-e1a8-dba4cb3097ee"
      },
      "outputs": [],
      "source": [
        "prediction.predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can <a href=\"https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects\" target=\"_blank\">delete the Google Cloud\n",
        "project</a> you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_vKniMq9ZX"
      },
      "outputs": [],
      "source": [
        "# Undeploy model from endpoint and delete endpoint\n",
        "endpoint.undeploy_all()\n",
        "endpoint.delete()\n",
        "\n",
        "# Delete BigQuery dataset, including the BigQuery ML model\n",
        "! bq rm -r -f $PROJECT_ID:$BQ_DATASET_NAME"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
